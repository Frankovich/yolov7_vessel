Lmod has detected the following error: The following module(s) are unknown:
"Anaconda/2020.11"

Please check the spelling or version number. Also try "module spider ..."
It is also possible your cache file is out-of-date; it may help to try:
  $ module --ignore-cache load "Anaconda/2020.11"

Also make sure that all modulefiles written in TCL start with the string
#%Module




Currently Loaded Modules:
  1) shared                              6) useful_scripts
  2) slurm/20.11.9                       7) DefaultModules
  3) apps                                8) craype-x86-rome
  4) site/tinkercliffs/easybuild/setup   9) craype-network-infiniband
  5) cray

 

WARNING: A conda environment already exists at '/apps/easybuild/software/tinkercliffs-rome/Anaconda3/2020.11/envs/mypy3'
Remove existing environment (y/[n])? 

CondaSystemExit: Exiting.

Collecting package metadata (current_repodata.json): ...working... done
Solving environment: ...working... done

## Package Plan ##

  environment location: /apps/easybuild/software/tinkercliffs-rome/Anaconda3/2020.11/envs/mypy3

  added / updated specs:
    - ipykernel


The following packages will be downloaded:

    package                    |            build
    ---------------------------|-----------------
    jupyter_client-7.1.2       |     pyhd3eb1b0_0          93 KB
    openssl-1.1.1w             |       h7f8727e_0         3.7 MB
    ------------------------------------------------------------
                                           Total:         3.8 MB

The following NEW packages will be INSTALLED:

  asttokens          pkgs/main/noarch::asttokens-2.0.5-pyhd3eb1b0_0
  backcall           pkgs/main/noarch::backcall-0.2.0-pyhd3eb1b0_0
  comm               pkgs/main/linux-64::comm-0.1.2-py38h06a4308_0
  debugpy            pkgs/main/linux-64::debugpy-1.6.7-py38h6a678d5_0
  decorator          pkgs/main/noarch::decorator-5.1.1-pyhd3eb1b0_0
  entrypoints        pkgs/main/linux-64::entrypoints-0.4-py38h06a4308_0
  executing          pkgs/main/noarch::executing-0.8.3-pyhd3eb1b0_0
  ipykernel          pkgs/main/linux-64::ipykernel-6.25.0-py38h2f386ee_0
  ipython            pkgs/main/linux-64::ipython-8.12.2-py38h06a4308_0
  jedi               pkgs/main/linux-64::jedi-0.18.1-py38h06a4308_1
  jupyter_client     pkgs/main/noarch::jupyter_client-7.1.2-pyhd3eb1b0_0
  jupyter_core       pkgs/main/linux-64::jupyter_core-5.3.0-py38h06a4308_0
  libsodium          pkgs/main/linux-64::libsodium-1.0.18-h7b6447c_0
  matplotlib-inline  pkgs/main/linux-64::matplotlib-inline-0.1.6-py38h06a4308_0
  nest-asyncio       pkgs/main/linux-64::nest-asyncio-1.5.6-py38h06a4308_0
  parso              pkgs/main/noarch::parso-0.8.3-pyhd3eb1b0_0
  pexpect            pkgs/main/noarch::pexpect-4.8.0-pyhd3eb1b0_3
  pickleshare        pkgs/main/noarch::pickleshare-0.7.5-pyhd3eb1b0_1003
  platformdirs       pkgs/main/linux-64::platformdirs-3.10.0-py38h06a4308_0
  prompt-toolkit     pkgs/main/linux-64::prompt-toolkit-3.0.36-py38h06a4308_0
  psutil             pkgs/main/linux-64::psutil-5.9.0-py38h5eee18b_0
  ptyprocess         pkgs/main/noarch::ptyprocess-0.7.0-pyhd3eb1b0_2
  pure_eval          pkgs/main/noarch::pure_eval-0.2.2-pyhd3eb1b0_0
  pygments           pkgs/main/linux-64::pygments-2.15.1-py38h06a4308_1
  pyzmq              pkgs/main/linux-64::pyzmq-25.1.0-py38h6a678d5_0
  stack_data         pkgs/main/noarch::stack_data-0.2.0-pyhd3eb1b0_0
  traitlets          pkgs/main/linux-64::traitlets-5.7.1-py38h06a4308_0
  typing_extensions  pkgs/main/linux-64::typing_extensions-4.7.1-py38h06a4308_0
  wcwidth            pkgs/main/noarch::wcwidth-0.2.5-pyhd3eb1b0_0
  zeromq             pkgs/main/linux-64::zeromq-4.3.4-h2531618_0

The following packages will be UPDATED:

  ca-certificates                      2022.4.26-h06a4308_0 --> 2023.08.22-h06a4308_0
  certifi                          2021.10.8-py38h06a4308_2 --> 2023.7.22-py38h06a4308_0
  libgcc-ng                               9.3.0-h5101ec6_17 --> 11.2.0-h1234567_1
  libgomp                                 9.3.0-h5101ec6_17 --> 11.2.0-h1234567_1
  libstdcxx-ng                            9.3.0-hd4cf53a_17 --> 11.2.0-h1234567_1
  openssl                                 1.1.1o-h7f8727e_0 --> 1.1.1w-h7f8727e_0


Proceed ([y]/n)? 

Downloading and Extracting Packages
openssl-1.1.1w       | 3.7 MB    |            |   0% openssl-1.1.1w       | 3.7 MB    | ######5    |  66% openssl-1.1.1w       | 3.7 MB    | ########## | 100% 
jupyter_client-7.1.2 | 93 KB     |            |   0% jupyter_client-7.1.2 | 93 KB     | ########## | 100% jupyter_client-7.1.2 | 93 KB     | ########## | 100% 
Preparing transaction: ...working... done
Verifying transaction: ...working... failed

EnvironmentNotWritableError: The current user does not have write permissions to the target environment.
  environment location: /apps/easybuild/software/tinkercliffs-rome/Anaconda3/2020.11/envs/mypy3
  uid: 7643359
  gid: 7643359


Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: matplotlib>=3.2.2 in /apps/easybuild/software/tinkercliffs-rome/Anaconda3/2020.11/envs/mypy3/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (3.5.1)
Requirement already satisfied: numpy<1.24.0,>=1.18.5 in /apps/easybuild/software/tinkercliffs-rome/Anaconda3/2020.11/envs/mypy3/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (1.21.5)
Collecting opencv-python>=4.1.1
  Using cached opencv_python-4.8.1.78-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.7 MB)
Requirement already satisfied: Pillow>=7.1.2 in /apps/easybuild/software/tinkercliffs-rome/Anaconda3/2020.11/envs/mypy3/lib/python3.8/site-packages (from -r requirements.txt (line 7)) (9.0.1)
Collecting PyYAML>=5.3.1
  Using cached PyYAML-6.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (736 kB)
Collecting requests>=2.23.0
  Using cached requests-2.31.0-py3-none-any.whl (62 kB)
Collecting scipy>=1.4.1
  Using cached scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)
Collecting torch!=1.12.0,>=1.7.0
  Using cached torch-2.1.0-cp38-cp38-manylinux1_x86_64.whl (670.2 MB)
Collecting torchvision!=0.13.0,>=0.8.1
  Using cached torchvision-0.16.0-cp38-cp38-manylinux1_x86_64.whl (6.9 MB)
Collecting tqdm>=4.41.0
  Using cached tqdm-4.66.1-py3-none-any.whl (78 kB)
Collecting protobuf<4.21.3
  Using cached protobuf-4.21.2-cp37-abi3-manylinux2014_x86_64.whl (407 kB)
Collecting tensorboard>=2.4.1
  Using cached tensorboard-2.14.0-py3-none-any.whl (5.5 MB)
Collecting pandas>=1.1.4
  Using cached pandas-2.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)
Collecting seaborn>=0.11.0
  Using cached seaborn-0.13.0-py3-none-any.whl (294 kB)
Collecting ipython
  Using cached ipython-8.12.3-py3-none-any.whl (798 kB)
Collecting psutil
  Using cached psutil-5.9.5-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (282 kB)
Collecting thop
  Using cached thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)
Requirement already satisfied: cycler>=0.10 in /apps/easybuild/software/tinkercliffs-rome/Anaconda3/2020.11/envs/mypy3/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.11.0)
Requirement already satisfied: kiwisolver>=1.0.1 in /apps/easybuild/software/tinkercliffs-rome/Anaconda3/2020.11/envs/mypy3/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.3.2)
Requirement already satisfied: pyparsing>=2.2.1 in /apps/easybuild/software/tinkercliffs-rome/Anaconda3/2020.11/envs/mypy3/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (3.0.4)
Requirement already satisfied: packaging>=20.0 in /apps/easybuild/software/tinkercliffs-rome/Anaconda3/2020.11/envs/mypy3/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (21.3)
Requirement already satisfied: fonttools>=4.22.0 in /apps/easybuild/software/tinkercliffs-rome/Anaconda3/2020.11/envs/mypy3/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (4.25.0)
Requirement already satisfied: python-dateutil>=2.7 in /apps/easybuild/software/tinkercliffs-rome/Anaconda3/2020.11/envs/mypy3/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.2)
Collecting idna<4,>=2.5
  Using cached idna-3.4-py3-none-any.whl (61 kB)
Collecting urllib3<3,>=1.21.1
  Using cached urllib3-2.0.6-py3-none-any.whl (123 kB)
Requirement already satisfied: certifi>=2017.4.17 in /apps/easybuild/software/tinkercliffs-rome/Anaconda3/2020.11/envs/mypy3/lib/python3.8/site-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2021.10.8)
Collecting charset-normalizer<4,>=2
  Using cached charset_normalizer-3.3.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)
Collecting filelock
  Using cached filelock-3.12.4-py3-none-any.whl (11 kB)
Collecting nvidia-cuda-cupti-cu12==12.1.105
  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)
Collecting nvidia-cusolver-cu12==11.4.5.107
  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)
Collecting networkx
  Using cached networkx-3.1-py3-none-any.whl (2.1 MB)
Collecting nvidia-nvtx-cu12==12.1.105
  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)
Collecting nvidia-cufft-cu12==11.0.2.54
  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)
Collecting jinja2
  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)
Collecting sympy
  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)
Collecting nvidia-cuda-runtime-cu12==12.1.105
  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)
Collecting nvidia-curand-cu12==10.3.2.106
  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)
Collecting nvidia-cusparse-cu12==12.1.0.106
  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)
Collecting nvidia-nccl-cu12==2.18.1
  Using cached nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)
Collecting nvidia-cuda-nvrtc-cu12==12.1.105
  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)
Collecting fsspec
  Using cached fsspec-2023.9.2-py3-none-any.whl (173 kB)
Collecting typing-extensions
  Using cached typing_extensions-4.8.0-py3-none-any.whl (31 kB)
Collecting nvidia-cublas-cu12==12.1.3.1
  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)
Collecting nvidia-cudnn-cu12==8.9.2.26
  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)
Collecting triton==2.1.0
  Using cached triton-2.1.0-0-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)
Collecting nvidia-nvjitlink-cu12
  Using cached nvidia_nvjitlink_cu12-12.2.140-py3-none-manylinux1_x86_64.whl (20.2 MB)
Collecting markdown>=2.6.8
  Using cached Markdown-3.5-py3-none-any.whl (101 kB)
Collecting absl-py>=0.4
  Using cached absl_py-2.0.0-py3-none-any.whl (130 kB)
Collecting google-auth-oauthlib<1.1,>=0.5
  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)
Collecting grpcio>=1.48.2
  Using cached grpcio-1.59.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)
Requirement already satisfied: wheel>=0.26 in /apps/easybuild/software/tinkercliffs-rome/Anaconda3/2020.11/envs/mypy3/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.37.1)
Collecting google-auth<3,>=1.6.3
  Using cached google_auth-2.23.3-py2.py3-none-any.whl (182 kB)
Requirement already satisfied: setuptools>=41.0.0 in /apps/easybuild/software/tinkercliffs-rome/Anaconda3/2020.11/envs/mypy3/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (61.2.0)
Collecting tensorboard-data-server<0.8.0,>=0.7.0
  Using cached tensorboard_data_server-0.7.1-py3-none-manylinux2014_x86_64.whl (6.6 MB)
Collecting werkzeug>=1.0.1
  Using cached werkzeug-3.0.0-py3-none-any.whl (226 kB)
Collecting tzdata>=2022.1
  Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB)
Collecting pytz>=2020.1
  Using cached pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)
Collecting pygments>=2.4.0
  Using cached Pygments-2.16.1-py3-none-any.whl (1.2 MB)
Collecting pickleshare
  Using cached pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)
Collecting backcall
  Using cached backcall-0.2.0-py2.py3-none-any.whl (11 kB)
Collecting traitlets>=5
  Using cached traitlets-5.11.2-py3-none-any.whl (83 kB)
Collecting stack-data
  Using cached stack_data-0.6.3-py3-none-any.whl (24 kB)
Collecting jedi>=0.16
  Using cached jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)
Collecting decorator
  Using cached decorator-5.1.1-py3-none-any.whl (9.1 kB)
Collecting pexpect>4.3
  Using cached pexpect-4.8.0-py2.py3-none-any.whl (59 kB)
Collecting matplotlib-inline
  Using cached matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)
Collecting prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30
  Using cached prompt_toolkit-3.0.39-py3-none-any.whl (385 kB)
Collecting rsa<5,>=3.1.4
  Using cached rsa-4.9-py3-none-any.whl (34 kB)
Collecting pyasn1-modules>=0.2.1
  Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)
Collecting cachetools<6.0,>=2.0.0
  Using cached cachetools-5.3.1-py3-none-any.whl (9.3 kB)
Collecting requests-oauthlib>=0.7.0
  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)
Collecting parso<0.9.0,>=0.8.3
  Using cached parso-0.8.3-py2.py3-none-any.whl (100 kB)
Collecting importlib-metadata>=4.4
  Using cached importlib_metadata-6.8.0-py3-none-any.whl (22 kB)
Collecting zipp>=0.5
  Using cached zipp-3.17.0-py3-none-any.whl (7.4 kB)
Collecting ptyprocess>=0.5
  Using cached ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)
Collecting wcwidth
  Using cached wcwidth-0.2.8-py2.py3-none-any.whl (31 kB)
Collecting pyasn1<0.6.0,>=0.4.6
  Using cached pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)
Requirement already satisfied: six>=1.5 in /apps/easybuild/software/tinkercliffs-rome/Anaconda3/2020.11/envs/mypy3/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.16.0)
Collecting oauthlib>=3.0.0
  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)
Collecting MarkupSafe>=2.1.1
  Using cached MarkupSafe-2.1.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)
Collecting asttokens>=2.1.0
  Using cached asttokens-2.4.0-py2.py3-none-any.whl (27 kB)
Collecting pure-eval
  Using cached pure_eval-0.2.2-py3-none-any.whl (11 kB)
Collecting executing>=1.2.0
  Using cached executing-2.0.0-py2.py3-none-any.whl (24 kB)
Collecting mpmath>=0.19
  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)
Installing collected packages: urllib3, pyasn1, nvidia-nvjitlink-cu12, idna, charset-normalizer, zipp, rsa, requests, pyasn1-modules, oauthlib, nvidia-cusparse-cu12, nvidia-cublas-cu12, mpmath, MarkupSafe, filelock, cachetools, wcwidth, tzdata, typing-extensions, triton, traitlets, sympy, requests-oauthlib, pytz, pure-eval, ptyprocess, parso, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusolver-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, networkx, jinja2, importlib-metadata, google-auth, fsspec, executing, asttokens, werkzeug, torch, tensorboard-data-server, stack-data, pygments, protobuf, prompt-toolkit, pickleshare, pexpect, pandas, matplotlib-inline, markdown, jedi, grpcio, google-auth-oauthlib, decorator, backcall, absl-py, tqdm, torchvision, thop, tensorboard, seaborn, scipy, PyYAML, psutil, opencv-python, ipython
  WARNING: The script normalizer is installed in '/home/willf20/.local/bin' which is not on PATH.
  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.
  WARNING: The scripts pyrsa-decrypt, pyrsa-encrypt, pyrsa-keygen, pyrsa-priv2pub, pyrsa-sign and pyrsa-verify are installed in '/home/willf20/.local/bin' which is not on PATH.
  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.
  WARNING: The script isympy is installed in '/home/willf20/.local/bin' which is not on PATH.
  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.
  WARNING: The scripts convert-caffe2-to-onnx, convert-onnx-to-caffe2 and torchrun are installed in '/home/willf20/.local/bin' which is not on PATH.
  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.
  WARNING: The script pygmentize is installed in '/home/willf20/.local/bin' which is not on PATH.
  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.
  WARNING: The script markdown_py is installed in '/home/willf20/.local/bin' which is not on PATH.
  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.
  WARNING: The script google-oauthlib-tool is installed in '/home/willf20/.local/bin' which is not on PATH.
  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.
  WARNING: The script tqdm is installed in '/home/willf20/.local/bin' which is not on PATH.
  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.
  WARNING: The script tensorboard is installed in '/home/willf20/.local/bin' which is not on PATH.
  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.
  WARNING: The scripts ipython and ipython3 are installed in '/home/willf20/.local/bin' which is not on PATH.
  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.
Successfully installed MarkupSafe-2.1.3 PyYAML-6.0.1 absl-py-2.0.0 asttokens-2.4.0 backcall-0.2.0 cachetools-5.3.1 charset-normalizer-3.3.0 decorator-5.1.1 executing-2.0.0 filelock-3.12.4 fsspec-2023.9.2 google-auth-2.23.3 google-auth-oauthlib-1.0.0 grpcio-1.59.0 idna-3.4 importlib-metadata-6.8.0 ipython-8.12.3 jedi-0.19.1 jinja2-3.1.2 markdown-3.5 matplotlib-inline-0.1.6 mpmath-1.3.0 networkx-3.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.2.140 nvidia-nvtx-cu12-12.1.105 oauthlib-3.2.2 opencv-python-4.8.1.78 pandas-2.0.3 parso-0.8.3 pexpect-4.8.0 pickleshare-0.7.5 prompt-toolkit-3.0.39 protobuf-4.21.2 psutil-5.9.5 ptyprocess-0.7.0 pure-eval-0.2.2 pyasn1-0.5.0 pyasn1-modules-0.3.0 pygments-2.16.1 pytz-2023.3.post1 requests-2.31.0 requests-oauthlib-1.3.1 rsa-4.9 scipy-1.10.1 seaborn-0.13.0 stack-data-0.6.3 sympy-1.12 tensorboard-2.14.0 tensorboard-data-server-0.7.1 thop-0.1.1.post2209072238 torch-2.1.0 torchvision-0.16.0 tqdm-4.66.1 traitlets-5.11.2 triton-2.1.0 typing-extensions-4.8.0 tzdata-2023.3 urllib3-2.0.6 wcwidth-0.2.8 werkzeug-3.0.0 zipp-3.17.0
cat: pytorch_config.sh: No such file or directory
pytorch_config output
import argparse
import time
from pathlib import Path

import cv2
import torch
import torch.backends.cudnn as cudnn
from numpy import random

from models.experimental import attempt_load
from utils.datasets import LoadStreams, LoadImages
from utils.general import check_img_size, check_requirements, check_imshow, non_max_suppression, apply_classifier, \
    scale_coords, xyxy2xywh, strip_optimizer, set_logging, increment_path
from utils.plots import plot_one_box
from utils.torch_utils import select_device, load_classifier, time_synchronized, TracedModel


def detect(save_img=False):
    source, weights, view_img, save_txt, imgsz, trace = opt.source, opt.weights, opt.view_img, opt.save_txt, opt.img_size, not opt.no_trace
    save_img = not opt.nosave and not source.endswith('.txt')  # save inference images
    webcam = source.isnumeric() or source.endswith('.txt') or source.lower().startswith(
        ('rtsp://', 'rtmp://', 'http://', 'https://'))

    # Directories
    save_dir = Path(increment_path(Path(opt.project) / opt.name, exist_ok=opt.exist_ok))  # increment run
    (save_dir / 'labels' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # make dir

    # Initialize
    set_logging()
    device = select_device(opt.device)
    half = device.type != 'cpu'  # half precision only supported on CUDA

    # Load model
    print(f"Attempting to load model with weights: {weights}, on device: {device}")
    model = attempt_load(weights, map_location=device)  # load FP32 model
    stride = int(model.stride.max())  # model stride
    imgsz = check_img_size(imgsz, s=stride)  # check img_size

    if trace:
        model = TracedModel(model, device, opt.img_size)

    if half:
        model.half()  # to FP16

    # Second-stage classifier
    classify = False
    if classify:
        modelc = load_classifier(name='resnet101', n=2)  # initialize
        modelc.load_state_dict(torch.load('weights/resnet101.pt', map_location=device)['model']).to(device).eval()

    # Set Dataloader
    vid_path, vid_writer = None, None
    if webcam:
        view_img = check_imshow()
        cudnn.benchmark = True  # set True to speed up constant image size inference
        dataset = LoadStreams(source, img_size=imgsz, stride=stride)
    else:
        dataset = LoadImages(source, img_size=imgsz, stride=stride)

    # Get names and colors
    names = model.module.names if hasattr(model, 'module') else model.names
    colors = [[random.randint(0, 255) for _ in range(3)] for _ in names]

    # Run inference
    if device.type != 'cpu':
        model(torch.zeros(1, 3, imgsz, imgsz).to(device).type_as(next(model.parameters())))  # run once
    old_img_w = old_img_h = imgsz
    old_img_b = 1

    t0 = time.time()

    processed_images = 0
    images_without_objects = 0

    for path, img, im0s, vid_cap in dataset:
        
        processed_images += 1
        
        img = torch.from_numpy(img).to(device)
        img = img.half() if half else img.float()  # uint8 to fp16/32
        img /= 255.0  # 0 - 255 to 0.0 - 1.0
        if img.ndimension() == 3:
            img = img.unsqueeze(0)

        # Warmup
        if device.type != 'cpu' and (old_img_b != img.shape[0] or old_img_h != img.shape[2] or old_img_w != img.shape[3]):
            old_img_b = img.shape[0]
            old_img_h = img.shape[2]
            old_img_w = img.shape[3]
            for i in range(3):
                model(img, augment=opt.augment)[0]

        # Inference
        t1 = time_synchronized()
        with torch.no_grad():   # Calculating gradients would cause a GPU memory leak
            pred = model(img, augment=opt.augment)[0]
        t2 = time_synchronized()

        # Apply NMS
        pred = non_max_suppression(pred, opt.conf_thres, opt.iou_thres, classes=opt.classes, agnostic=opt.agnostic_nms)
        t3 = time_synchronized()

        # Apply Classifier
        if classify:
            pred = apply_classifier(pred, modelc, img, im0s)


        # Process detections
        for i, det in enumerate(pred):  # detections per image
            if webcam:  # batch_size >= 1
                p, s, im0, frame = path[i], '%g: ' % i, im0s[i].copy(), dataset.count
            else:
                p, s, im0, frame = path, '', im0s, getattr(dataset, 'frame', 0)

            p = Path(p)  # to Path
            save_path = str(save_dir / p.name)  # img.jpg
            txt_path = str(save_dir / 'labels' / p.stem) + ('' if dataset.mode == 'image' else f'_{frame}')  # img.txt
            gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh
            if len(det):
                # Rescale boxes from img_size to im0 size
                det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()

                # Print results
                for c in det[:, -1].unique():
                    n = (det[:, -1] == c).sum()  # detections per class
                    s += f"{n} {names[int(c)]}{'s' * (n > 1)}, "  # add to string

                max_area = 0
                largest_object = None
                for *xyxy, conf, cls in reversed(det):
                    x1, y1, x2, y2 = map(int, xyxy)
                    area = (x2 - x1) * (y2 - y1)
                    if area > max_area:
                        max_area = area
                        largest_object = (x1, y1, x2, y2)

                if largest_object:
                    x1, y1, x2, y2 = largest_object
                    cropped_img = im0[y1:y2, x1:x2]
                    cropped_save_path = str(save_dir / f"{p.stem}.png")
                    cv2.imwrite(cropped_save_path, cropped_img)
                    print(f"The cropped image of the largest object is saved at: {cropped_save_path}")

            else:
                images_without_objects += 1

            # Print time (inference + NMS)
            print(f'{s}Done. ({(1E3 * (t2 - t1)):.1f}ms) Inference, ({(1E3 * (t3 - t2)):.1f}ms) NMS')

            # Stream results
            if view_img:
                cv2.imshow(str(p), im0)
                cv2.waitKey(1)  # 1 millisecond

    if save_txt or save_img:
        s = f"\n{len(list(save_dir.glob('labels/*.txt')))} labels saved to {save_dir / 'labels'}" if save_txt else ''
        #print(f"Results saved to {save_dir}{s}")

    print(f"Total images processed: {processed_images}")
    print(f"Images with detected objects: {processed_images - images_without_objects}")
    print(f"Images without detected objects: {images_without_objects}")

    print(f'Done. ({time.time() - t0:.3f}s)')


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--weights', nargs='+', type=str, default='yolov7.pt', help='model.pt path(s)')
    parser.add_argument('--source', type=str, default='inference/images', help='source')  # file/folder, 0 for webcam
    parser.add_argument('--img-size', type=int, default=640, help='inference size (pixels)')
    parser.add_argument('--conf-thres', type=float, default=0.25, help='object confidence threshold')
    parser.add_argument('--iou-thres', type=float, default=0.45, help='IOU threshold for NMS')
    parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')
    parser.add_argument('--view-img', action='store_true', help='display results')
    parser.add_argument('--save-txt', action='store_true', help='save results to *.txt')
    parser.add_argument('--save-conf', action='store_true', help='save confidences in --save-txt labels')
    parser.add_argument('--nosave', action='store_true', help='do not save images/videos')
    parser.add_argument('--classes', nargs='+', type=int, help='filter by class: --class 0, or --class 0 2 3')
    parser.add_argument('--agnostic-nms', action='store_true', help='class-agnostic NMS')
    parser.add_argument('--augment', action='store_true', help='augmented inference')
    parser.add_argument('--update', action='store_true', help='update all models')
    parser.add_argument('--project', default='runs/detect', help='save results to project/name')
    parser.add_argument('--name', default='exp', help='save results to project/name')
    parser.add_argument('--exist-ok', action='store_true', help='existing project/name ok, do not increment')
    parser.add_argument('--no-trace', action='store_true', help='don`t trace model')
    opt = parser.parse_args()
    print(opt)
    #check_requirements(exclude=('pycocotools', 'thop'))

    with torch.no_grad():
        if opt.update:  # update all models (to fix SourceChangeWarning)
            for opt.weights in ['yolov7.pt']:
                detect()
                strip_optimizer(opt.weights)
        else:
            detect()
start load env and run python
YOLOR ðŸš€ 2023-10-2 torch 2.1.0+cu121 CPU

/home/willf20/.local/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Model Summary: 792 layers, 151687420 parameters, 817020 gradients, 210.5 GFLOPS
slurmstepd: error: *** JOB 1695432 ON tc022 CANCELLED AT 2023-10-10T11:07:58 ***
