srun: error: Unable to create step for job 1695638: Invalid generic resource (gres) specification

Currently Loaded Modules:
  1) shared                              6) useful_scripts
  2) slurm/20.11.9                       7) DefaultModules
  3) apps                                8) craype-x86-rome
  4) site/tinkercliffs/easybuild/setup   9) craype-network-infiniband
  5) cray                               10) Anaconda3/2020.11

 

/cm/local/apps/slurm/var/spool/job1695638/slurm_script: line 18: nvidia-smi: command not found
WARNING: A conda environment already exists at '/home/willf20/.conda/envs/pytorch'
Remove existing environment (y/[n])? 

CondaSystemExit: Exiting.

Collecting package metadata (current_repodata.json): ...working... done
Solving environment: ...working... done

# All requested packages already installed.

Requirement already satisfied: matplotlib>=3.2.2 in /home/willf20/.conda/envs/pytorch/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (3.7.3)
Requirement already satisfied: numpy<1.24.0,>=1.18.5 in /home/willf20/.conda/envs/pytorch/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (1.23.5)
Requirement already satisfied: opencv-python>=4.1.1 in /home/willf20/.local/lib/python3.8/site-packages (from -r requirements.txt (line 6)) (4.8.1.78)
Requirement already satisfied: Pillow>=7.1.2 in /home/willf20/.conda/envs/pytorch/lib/python3.8/site-packages (from -r requirements.txt (line 7)) (10.0.1)
Requirement already satisfied: PyYAML>=5.3.1 in /home/willf20/.local/lib/python3.8/site-packages (from -r requirements.txt (line 8)) (6.0.1)
Requirement already satisfied: requests>=2.23.0 in /home/willf20/.local/lib/python3.8/site-packages (from -r requirements.txt (line 9)) (2.31.0)
Requirement already satisfied: scipy>=1.4.1 in /home/willf20/.local/lib/python3.8/site-packages (from -r requirements.txt (line 10)) (1.10.1)
Requirement already satisfied: torch!=1.12.0,>=1.7.0 in /home/willf20/.local/lib/python3.8/site-packages (from -r requirements.txt (line 11)) (2.1.0)
Requirement already satisfied: torchvision!=0.13.0,>=0.8.1 in /home/willf20/.local/lib/python3.8/site-packages (from -r requirements.txt (line 12)) (0.16.0)
Requirement already satisfied: tqdm>=4.41.0 in /home/willf20/.local/lib/python3.8/site-packages (from -r requirements.txt (line 13)) (4.66.1)
Requirement already satisfied: protobuf<4.21.3 in /home/willf20/.local/lib/python3.8/site-packages (from -r requirements.txt (line 14)) (4.21.2)
Requirement already satisfied: tensorboard>=2.4.1 in /home/willf20/.local/lib/python3.8/site-packages (from -r requirements.txt (line 17)) (2.14.0)
Requirement already satisfied: pandas>=1.1.4 in /home/willf20/.local/lib/python3.8/site-packages (from -r requirements.txt (line 21)) (2.0.3)
Requirement already satisfied: seaborn>=0.11.0 in /home/willf20/.local/lib/python3.8/site-packages (from -r requirements.txt (line 22)) (0.13.0)
Requirement already satisfied: ipython in /home/willf20/.local/lib/python3.8/site-packages (from -r requirements.txt (line 34)) (8.12.3)
Requirement already satisfied: psutil in /home/willf20/.local/lib/python3.8/site-packages (from -r requirements.txt (line 35)) (5.9.5)
Requirement already satisfied: thop in /home/willf20/.local/lib/python3.8/site-packages (from -r requirements.txt (line 36)) (0.1.1.post2209072238)
Requirement already satisfied: contourpy>=1.0.1 in /home/willf20/.conda/envs/pytorch/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.1.1)
Requirement already satisfied: cycler>=0.10 in /home/willf20/.conda/envs/pytorch/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.12.1)
Requirement already satisfied: fonttools>=4.22.0 in /home/willf20/.conda/envs/pytorch/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (4.43.1)
Requirement already satisfied: kiwisolver>=1.0.1 in /home/willf20/.conda/envs/pytorch/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.4.5)
Requirement already satisfied: packaging>=20.0 in /home/willf20/.conda/envs/pytorch/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (23.1)
Requirement already satisfied: pyparsing>=2.3.1 in /home/willf20/.conda/envs/pytorch/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (3.1.1)
Requirement already satisfied: python-dateutil>=2.7 in /home/willf20/.conda/envs/pytorch/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.2)
Requirement already satisfied: importlib-resources>=3.2.0 in /home/willf20/.conda/envs/pytorch/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (6.1.0)
Requirement already satisfied: charset-normalizer<4,>=2 in /home/willf20/.local/lib/python3.8/site-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (3.3.0)
Requirement already satisfied: idna<4,>=2.5 in /home/willf20/.local/lib/python3.8/site-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (3.4)
Requirement already satisfied: urllib3<3,>=1.21.1 in /home/willf20/.local/lib/python3.8/site-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2.0.6)
Requirement already satisfied: certifi>=2017.4.17 in /home/willf20/.conda/envs/pytorch/lib/python3.8/site-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2023.7.22)
Requirement already satisfied: filelock in /home/willf20/.local/lib/python3.8/site-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.12.4)
Requirement already satisfied: typing-extensions in /home/willf20/.local/lib/python3.8/site-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (4.8.0)
Requirement already satisfied: sympy in /home/willf20/.local/lib/python3.8/site-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (1.12)
Requirement already satisfied: networkx in /home/willf20/.local/lib/python3.8/site-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.1)
Requirement already satisfied: jinja2 in /home/willf20/.local/lib/python3.8/site-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.1.2)
Requirement already satisfied: fsspec in /home/willf20/.local/lib/python3.8/site-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (2023.9.2)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/willf20/.local/lib/python3.8/site-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (12.1.105)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/willf20/.local/lib/python3.8/site-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (12.1.105)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/willf20/.local/lib/python3.8/site-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (12.1.105)
Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/willf20/.local/lib/python3.8/site-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (8.9.2.26)
Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/willf20/.local/lib/python3.8/site-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (12.1.3.1)
Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/willf20/.local/lib/python3.8/site-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (11.0.2.54)
Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/willf20/.local/lib/python3.8/site-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (10.3.2.106)
Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/willf20/.local/lib/python3.8/site-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (11.4.5.107)
Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/willf20/.local/lib/python3.8/site-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (12.1.0.106)
Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/willf20/.local/lib/python3.8/site-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (2.18.1)
Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/willf20/.local/lib/python3.8/site-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (12.1.105)
Requirement already satisfied: triton==2.1.0 in /home/willf20/.local/lib/python3.8/site-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (2.1.0)
Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/willf20/.local/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (12.2.140)
Requirement already satisfied: absl-py>=0.4 in /home/willf20/.local/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (2.0.0)
Requirement already satisfied: grpcio>=1.48.2 in /home/willf20/.local/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.59.0)
Requirement already satisfied: google-auth<3,>=1.6.3 in /home/willf20/.local/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (2.23.3)
Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/willf20/.local/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.0.0)
Requirement already satisfied: markdown>=2.6.8 in /home/willf20/.local/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.5)
Requirement already satisfied: setuptools>=41.0.0 in /home/willf20/.conda/envs/pytorch/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (68.0.0)
Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/willf20/.local/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.7.1)
Requirement already satisfied: werkzeug>=1.0.1 in /home/willf20/.local/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.0.0)
Requirement already satisfied: wheel>=0.26 in /home/willf20/.conda/envs/pytorch/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.41.2)
Requirement already satisfied: pytz>=2020.1 in /home/willf20/.local/lib/python3.8/site-packages (from pandas>=1.1.4->-r requirements.txt (line 21)) (2023.3.post1)
Requirement already satisfied: tzdata>=2022.1 in /home/willf20/.local/lib/python3.8/site-packages (from pandas>=1.1.4->-r requirements.txt (line 21)) (2023.3)
Requirement already satisfied: backcall in /home/willf20/.local/lib/python3.8/site-packages (from ipython->-r requirements.txt (line 34)) (0.2.0)
Requirement already satisfied: decorator in /home/willf20/.local/lib/python3.8/site-packages (from ipython->-r requirements.txt (line 34)) (5.1.1)
Requirement already satisfied: jedi>=0.16 in /home/willf20/.local/lib/python3.8/site-packages (from ipython->-r requirements.txt (line 34)) (0.19.1)
Requirement already satisfied: matplotlib-inline in /home/willf20/.local/lib/python3.8/site-packages (from ipython->-r requirements.txt (line 34)) (0.1.6)
Requirement already satisfied: pickleshare in /home/willf20/.local/lib/python3.8/site-packages (from ipython->-r requirements.txt (line 34)) (0.7.5)
Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /home/willf20/.local/lib/python3.8/site-packages (from ipython->-r requirements.txt (line 34)) (3.0.39)
Requirement already satisfied: pygments>=2.4.0 in /home/willf20/.local/lib/python3.8/site-packages (from ipython->-r requirements.txt (line 34)) (2.16.1)
Requirement already satisfied: stack-data in /home/willf20/.local/lib/python3.8/site-packages (from ipython->-r requirements.txt (line 34)) (0.6.3)
Requirement already satisfied: traitlets>=5 in /home/willf20/.local/lib/python3.8/site-packages (from ipython->-r requirements.txt (line 34)) (5.11.2)
Requirement already satisfied: pexpect>4.3 in /home/willf20/.local/lib/python3.8/site-packages (from ipython->-r requirements.txt (line 34)) (4.8.0)
Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/willf20/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (5.3.1)
Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/willf20/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.3.0)
Requirement already satisfied: rsa<5,>=3.1.4 in /home/willf20/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (4.9)
Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/willf20/.local/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.3.1)
Requirement already satisfied: zipp>=3.1.0 in /home/willf20/.local/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib>=3.2.2->-r requirements.txt (line 4)) (3.17.0)
Requirement already satisfied: parso<0.9.0,>=0.8.3 in /home/willf20/.local/lib/python3.8/site-packages (from jedi>=0.16->ipython->-r requirements.txt (line 34)) (0.8.3)
Requirement already satisfied: importlib-metadata>=4.4 in /home/willf20/.local/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 17)) (6.8.0)
Requirement already satisfied: ptyprocess>=0.5 in /home/willf20/.local/lib/python3.8/site-packages (from pexpect>4.3->ipython->-r requirements.txt (line 34)) (0.7.0)
Requirement already satisfied: wcwidth in /home/willf20/.local/lib/python3.8/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython->-r requirements.txt (line 34)) (0.2.8)
Requirement already satisfied: six>=1.5 in /home/willf20/.conda/envs/pytorch/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.16.0)
Requirement already satisfied: MarkupSafe>=2.1.1 in /home/willf20/.local/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->-r requirements.txt (line 17)) (2.1.3)
Requirement already satisfied: executing>=1.2.0 in /home/willf20/.local/lib/python3.8/site-packages (from stack-data->ipython->-r requirements.txt (line 34)) (2.0.0)
Requirement already satisfied: asttokens>=2.1.0 in /home/willf20/.local/lib/python3.8/site-packages (from stack-data->ipython->-r requirements.txt (line 34)) (2.4.0)
Requirement already satisfied: pure-eval in /home/willf20/.local/lib/python3.8/site-packages (from stack-data->ipython->-r requirements.txt (line 34)) (0.2.2)
Requirement already satisfied: mpmath>=0.19 in /home/willf20/.local/lib/python3.8/site-packages (from sympy->torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (1.3.0)
Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/willf20/.local/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.5.0)
Requirement already satisfied: oauthlib>=3.0.0 in /home/willf20/.local/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.2.2)
#!/bin/bash

### pytorch_config.sh
###########################################################################
## environment & variable setup
####### job customization
#SBATCH -N 1
#SBATCH -n 16
#SBATCH -t 1:00:00
#SBATCH -p normal_q
####### end of job customization
# end of environment & variable setup
###########################################################################
#### add modules:
interact --account=personal --partition=a100_normal_q -N 1 -n 12 --gres=gpu:1
module load Anaconda3/2020.11
module list
nvidia-smi
conda create -n pytorch python=3.8 pip 
source activate pytorch
conda install ipykernel
pip install -r requirements.txt
#end of add modules
###########################################################################
###print script to keep a record of what is done
cat pytorch_config.sh
echo "pytorch_config output"
cat detect.py
###########################################################################
echo start load env and run python

source activate mypy3
python detect.py --weights yolov7-e6e.pt --classes 8 --source ../Downloads

exit;pytorch_config output
import argparse
import time
from pathlib import Path

import cv2
import torch
import torch.backends.cudnn as cudnn
from numpy import random

from models.experimental import attempt_load
from utils.datasets import LoadStreams, LoadImages
from utils.general import check_img_size, check_requirements, check_imshow, non_max_suppression, apply_classifier, \
    scale_coords, xyxy2xywh, strip_optimizer, set_logging, increment_path
from utils.plots import plot_one_box
from utils.torch_utils import select_device, load_classifier, time_synchronized, TracedModel


def detect(save_img=False):
    source, weights, view_img, save_txt, imgsz, trace = opt.source, opt.weights, opt.view_img, opt.save_txt, opt.img_size, not opt.no_trace
    save_img = not opt.nosave and not source.endswith('.txt')  # save inference images
    webcam = source.isnumeric() or source.endswith('.txt') or source.lower().startswith(
        ('rtsp://', 'rtmp://', 'http://', 'https://'))

    # Directories
    save_dir = Path(increment_path(Path(opt.project) / opt.name, exist_ok=opt.exist_ok))  # increment run
    (save_dir / 'labels' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # make dir

    # Initialize
    set_logging()
    device = select_device(opt.device)
    half = device.type != 'cpu'  # half precision only supported on CUDA

    # Load model
    print(f"Attempting to load model with weights: {weights}, on device: {device}")
    model = attempt_load(weights, map_location=device)  # load FP32 model
    stride = int(model.stride.max())  # model stride
    imgsz = check_img_size(imgsz, s=stride)  # check img_size

    if trace:
        model = TracedModel(model, device, opt.img_size)

    if half:
        model.half()  # to FP16

    # Second-stage classifier
    classify = False
    if classify:
        modelc = load_classifier(name='resnet101', n=2)  # initialize
        modelc.load_state_dict(torch.load('weights/resnet101.pt', map_location=device)['model']).to(device).eval()

    # Set Dataloader
    vid_path, vid_writer = None, None
    if webcam:
        view_img = check_imshow()
        cudnn.benchmark = True  # set True to speed up constant image size inference
        dataset = LoadStreams(source, img_size=imgsz, stride=stride)
    else:
        dataset = LoadImages(source, img_size=imgsz, stride=stride)

    # Get names and colors
    names = model.module.names if hasattr(model, 'module') else model.names
    colors = [[random.randint(0, 255) for _ in range(3)] for _ in names]

    # Run inference
    if device.type != 'cpu':
        model(torch.zeros(1, 3, imgsz, imgsz).to(device).type_as(next(model.parameters())))  # run once
    old_img_w = old_img_h = imgsz
    old_img_b = 1

    t0 = time.time()

    processed_images = 0
    images_without_objects = 0

    for path, img, im0s, vid_cap in dataset:
        
        processed_images += 1
        
        img = torch.from_numpy(img).to(device)
        img = img.half() if half else img.float()  # uint8 to fp16/32
        img /= 255.0  # 0 - 255 to 0.0 - 1.0
        if img.ndimension() == 3:
            img = img.unsqueeze(0)

        # Warmup
        if device.type != 'cpu' and (old_img_b != img.shape[0] or old_img_h != img.shape[2] or old_img_w != img.shape[3]):
            old_img_b = img.shape[0]
            old_img_h = img.shape[2]
            old_img_w = img.shape[3]
            for i in range(3):
                model(img, augment=opt.augment)[0]

        # Inference
        t1 = time_synchronized()
        with torch.no_grad():   # Calculating gradients would cause a GPU memory leak
            pred = model(img, augment=opt.augment)[0]
        t2 = time_synchronized()

        # Apply NMS
        pred = non_max_suppression(pred, opt.conf_thres, opt.iou_thres, classes=opt.classes, agnostic=opt.agnostic_nms)
        t3 = time_synchronized()

        # Apply Classifier
        if classify:
            pred = apply_classifier(pred, modelc, img, im0s)


        # Process detections
        for i, det in enumerate(pred):  # detections per image
            if webcam:  # batch_size >= 1
                p, s, im0, frame = path[i], '%g: ' % i, im0s[i].copy(), dataset.count
            else:
                p, s, im0, frame = path, '', im0s, getattr(dataset, 'frame', 0)

            p = Path(p)  # to Path
            save_path = str(save_dir / p.name)  # img.jpg
            txt_path = str(save_dir / 'labels' / p.stem) + ('' if dataset.mode == 'image' else f'_{frame}')  # img.txt
            gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh
            if len(det):
                # Rescale boxes from img_size to im0 size
                det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()

                # Print results
                for c in det[:, -1].unique():
                    n = (det[:, -1] == c).sum()  # detections per class
                    s += f"{n} {names[int(c)]}{'s' * (n > 1)}, "  # add to string

                max_area = 0
                largest_object = None
                for *xyxy, conf, cls in reversed(det):
                    x1, y1, x2, y2 = map(int, xyxy)
                    area = (x2 - x1) * (y2 - y1)
                    if area > max_area:
                        max_area = area
                        largest_object = (x1, y1, x2, y2)

                if largest_object:
                    x1, y1, x2, y2 = largest_object
                    cropped_img = im0[y1:y2, x1:x2]
                    cropped_save_path = str(save_dir / f"{p.stem}.png")
                    cv2.imwrite(cropped_save_path, cropped_img)
                    print(f"The cropped image of the largest object is saved at: {cropped_save_path}")

            else:
                images_without_objects += 1

            # Print time (inference + NMS)
            print(f'{s}Done. ({(1E3 * (t2 - t1)):.1f}ms) Inference, ({(1E3 * (t3 - t2)):.1f}ms) NMS')

            # Stream results
            if view_img:
                cv2.imshow(str(p), im0)
                cv2.waitKey(1)  # 1 millisecond

    if save_txt or save_img:
        s = f"\n{len(list(save_dir.glob('labels/*.txt')))} labels saved to {save_dir / 'labels'}" if save_txt else ''
        #print(f"Results saved to {save_dir}{s}")

    print(f"Total images processed: {processed_images}")
    print(f"Images with detected objects: {processed_images - images_without_objects}")
    print(f"Images without detected objects: {images_without_objects}")

    print(f'Done. ({time.time() - t0:.3f}s)')


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--weights', nargs='+', type=str, default='yolov7.pt', help='model.pt path(s)')
    parser.add_argument('--source', type=str, default='inference/images', help='source')  # file/folder, 0 for webcam
    parser.add_argument('--img-size', type=int, default=640, help='inference size (pixels)')
    parser.add_argument('--conf-thres', type=float, default=0.25, help='object confidence threshold')
    parser.add_argument('--iou-thres', type=float, default=0.45, help='IOU threshold for NMS')
    parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')
    parser.add_argument('--view-img', action='store_true', help='display results')
    parser.add_argument('--save-txt', action='store_true', help='save results to *.txt')
    parser.add_argument('--save-conf', action='store_true', help='save confidences in --save-txt labels')
    parser.add_argument('--nosave', action='store_true', help='do not save images/videos')
    parser.add_argument('--classes', nargs='+', type=int, help='filter by class: --class 0, or --class 0 2 3')
    parser.add_argument('--agnostic-nms', action='store_true', help='class-agnostic NMS')
    parser.add_argument('--augment', action='store_true', help='augmented inference')
    parser.add_argument('--update', action='store_true', help='update all models')
    parser.add_argument('--project', default='runs/detect', help='save results to project/name')
    parser.add_argument('--name', default='exp', help='save results to project/name')
    parser.add_argument('--exist-ok', action='store_true', help='existing project/name ok, do not increment')
    parser.add_argument('--no-trace', action='store_true', help='don`t trace model')
    opt = parser.parse_args()
    print(opt)
    #check_requirements(exclude=('pycocotools', 'thop'))

    with torch.no_grad():
        if opt.update:  # update all models (to fix SourceChangeWarning)
            for opt.weights in ['yolov7.pt']:
                detect()
                strip_optimizer(opt.weights)
        else:
            detect()
start load env and run python
YOLOR 🚀 2023-10-2 torch 2.1.0+cu121 CPU

/home/willf20/.local/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Model Summary: 792 layers, 151687420 parameters, 817020 gradients, 210.5 GFLOPS
slurmstepd: error: *** JOB 1695638 ON tc224 CANCELLED AT 2023-10-10T13:16:21 ***
